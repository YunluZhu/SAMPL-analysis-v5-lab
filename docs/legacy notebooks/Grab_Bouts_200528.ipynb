{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Bouts\n",
    "- Includes: \n",
    "    1. GrabFishAngelAll\n",
    "\n",
    "- Purpose of Python version by YZ:\n",
    "    1. Rewrite of analyzeFreeVerticalGrouped2.m & GrabFishAngleAll.m for faster runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules and functions\n",
    "\n",
    "import pandas as pd
from plot_functions.plt_tools import round_half_up \n",
    "import numpy as np # numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "# import itertools \n",
    "import os, glob, sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def grp_by_epoch(df):\n",
    "    '''Group df by 'epochNum'''\n",
    "    return df.groupby('epochNum', sort=False)\n",
    "\n",
    "def grp_by_swim(df,loco_index):\n",
    "    '''Get bouts, then group by 'col'''\n",
    "    return df.loc[df[loco_index] % 2 == 1].groupby(loco_index, as_index=False, sort=False)\n",
    "\n",
    "# def smooth_pdSeries(y, box_pts):\n",
    "#     '''\n",
    "#     smooth data using convolution\n",
    "#     input data type: y = pd.Series, box_ptx = int\n",
    "#     output data type: pd.Series with original index\n",
    "#     '''\n",
    "#     box = np.ones(box_pts)/box_pts\n",
    "#     y_smooth = np.convolve(y.values, box, mode='same')\n",
    "#     return pd.Series(data=y_smooth, index=y.index)\n",
    "\n",
    "# def smooth(y, box_pts):\n",
    "#     '''\n",
    "#     smooth data using convolution\n",
    "#     input data type: y = pd.Series, box_ptx = int\n",
    "#     output data type: np.array\n",
    "#     '''\n",
    "#     box = np.ones(box_pts)/box_pts\n",
    "#     y_smooth = np.convolve(y.values, box, mode='same')\n",
    "#     return y_smooth\n",
    "def smooth_series_ML(a,WSZ):\n",
    "    '''\n",
    "    Modified from Divakar's answer https://stackoverflow.com/questions/40443020/matlabs-smooth-implementation-n-point-moving-average-in-numpy-python\n",
    "    a: NumPy 1-D array containing the data to be smoothed\n",
    "    WSZ: smoothing window size needs, which must be odd number,\n",
    "    as in the original MATLAB implementation\n",
    "    '''\n",
    "    out0 = np.convolve(a,np.ones(WSZ,dtype=int),'valid')/WSZ    \n",
    "    r = np.arange(1,WSZ-1,2)\n",
    "    start = np.cumsum(a[:WSZ-1])[::2]/r\n",
    "    stop = (np.cumsum(a[:-WSZ:-1])[::2]/r)[::-1]\n",
    "    res = np.concatenate((  start , out0, stop  ))\n",
    "    return pd.Series(data=res, index=a.index)\n",
    "\n",
    "def smooth_ML(a,WSZ):\n",
    "    '''\n",
    "    Modified from Divakar's answer https://stackoverflow.com/questions/40443020/matlabs-smooth-implementation-n-point-moving-average-in-numpy-python\n",
    "    a: NumPy 1-D array containing the data to be smoothed\n",
    "    WSZ: smoothing window size needs, which must be odd number,\n",
    "    as in the original MATLAB implementation\n",
    "    '''\n",
    "    out0 = np.convolve(a,np.ones(WSZ,dtype=int),'valid')/WSZ    \n",
    "    r = np.arange(1,WSZ-1,2)\n",
    "    start = np.cumsum(a[:WSZ-1])[::2]/r\n",
    "    stop = (np.cumsum(a[:-WSZ:-1])[::2]/r)[::-1]\n",
    "    res = np.concatenate((  start , out0, stop  ))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "propulsion_threshold = 5  # mm/s, speed threshold above which samples are considered propulsion\n",
    "baseline_threshold = 1  # mm/s, speed threshold below which samples are considered at baseline (not propelling)\n",
    "sample_rate = 40  # Hz\n",
    "min_swim_interval = 0.1  # s, minimum swim interval duration\n",
    "post_bout_buf = math.ceil(0.1 * sample_rate)  # 4 frames\n",
    "pre_bout_buf = math.ceil(0.1 * sample_rate)  # 4 frames\n",
    "bout_window_half = math.ceil(0.3 * sample_rate)  # 12 frames\n",
    "sm_window = 3\n",
    "edge_chop = 5  # number of samples to remove from the beginning and end of each vector to account for edge effects (improper detection of fish body and movement)\n",
    "bout_long_tail = 40  # align prop bouts with longer duration (20 extra frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file from Analyze Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read analyzed epoch files\n",
    "\n",
    "# subjected to change\n",
    "file_path = os.getcwd() # need to be defined/entered when calling as a function or use command line input\n",
    "filenames = glob.glob(f\"{file_path}/data/*_analyzed_epochs.pkl\") # subject to change \n",
    "file_i = 0 # get 1 file for testing\n",
    "\n",
    "analyzed = pd.read_pickle(filenames[file_i])\n",
    "fish_length = pd.read_pickle(f\"./data/{file_i+1}_fish_length.pkl\")\n",
    "\n",
    "# find epochs with max speed above threshold\n",
    "speed_threshold = propulsion_threshold\n",
    "df = grp_by_epoch(analyzed).filter(\n",
    "    lambda g: np.nanmax(g['swimSpeed'].values) >= speed_threshold\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_swim_interval## Identify start and end of window when fish crosses threshold\n",
    "One way is to loop through all the epoch groups and every timepoint to find the start and end of each swim window. However, it takes ~8s to loop through one .dlm file in this way using the code below:\n",
    "```\n",
    "start = time.time()\n",
    "tmp = defaultdict(list)\n",
    "for epochNum, group in grp_by_epoch(df)[['swimSpeed']]:\n",
    "    for ind, spd in group.iterrows():\n",
    "        tmp[epochNum].append(ind)\n",
    "end = time.time()\n",
    "```\n",
    "Therefore, an alternative method is used here in order to directly apply all calculations to the whole data frame:\n",
    "\n",
    "1. assign a boolean column 'ifSwim'. True if swim speed excede the threshold\n",
    "2. convert boolean to int., True = 1, False = 0. Assign to a new column 'swimIndicator'\n",
    "3. to separate swim windoes between different epochs, set the start of each epoch to swimIndicator = 0\n",
    "4. apply diff().abs().cumsum() to 'swimIndicator', assign values to a new column 'locoIdx' (locomotion index). In 'locoIdx', a unique index is assigned for each window with a swim speed below or above the threshold. All windows that are identified as swim activities have odd indices and those with swim speed below the threshold have even indices\n",
    "5. filter for inter swim duration. Link 2 fast swim windows (odd locoIdx) that are closer than min_swim_interval by changing swimIndicators of the window between them (even locoIdx) from 0 to 1\n",
    "6. repeat step 4 to calculate adjusted locomotion indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find swim windows\n",
    "\n",
    "speed_threshold = propulsion_threshold\n",
    "spd_window = df[['epochNum','absTime','swimSpeed','angVel']]\n",
    "# assign boolean to determine whether swim speed excede threshold\n",
    "spd_window = spd_window.assign(\n",
    "    ifSwim = spd_window['swimSpeed'] >= speed_threshold\n",
    ")\n",
    "# transfer boolean to int\n",
    "spd_window = spd_window.assign(\n",
    "    swimIndicator = (spd_window['ifSwim']==True).astype(int)\n",
    ")\n",
    "# exclude bouts that start at the beginning of epochs by setting the beginning of each epoch to 0\n",
    "spd_window.loc[grp_by_epoch(spd_window)['swimIndicator'].transform('idxmin'), 'swimIndicator'] = 0\n",
    "# use cumsum to generate swim indices. All swims faster than threshold should have odd swim indices\n",
    "spd_window = spd_window.assign(\n",
    "    locoIDX = spd_window['swimIndicator'].diff().abs().cumsum()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if SpdWindStarts are realistically delayed from each other to constitute separate bouts. If not, link these bouts.\n",
    "# NOTE, MANUALLY CAPPING DETECTED FREQUENCY AT 5Hz\n",
    "# get the first timepoint of each swim window\n",
    "fast_win_st = grp_by_swim(spd_window,'locoIDX')[['locoIDX', 'absTime']].head(1)\n",
    "fast_win_ed = grp_by_swim(spd_window,'locoIDX')[['locoIDX', 'absTime']].tail(1).reset_index(drop=True)\n",
    "# delay between fast windows = fast_win_st[i+1] - fast_win_ed[i], therefore, drop the first fast window start\n",
    "fast_win_st_shift = fast_win_st.iloc[1:].reset_index(drop=True)\n",
    "# initialize the locomotion index adjustment calculator as a dataframe\n",
    "loco_idx_adj = fast_win_ed[['locoIDX']]\n",
    "# calculate swim delays (bout intervals).\n",
    "loco_idx_adj['swimDelay'] = fast_win_st_shift['absTime'] - fast_win_ed['absTime'] \n",
    "#  In the matlab code, each speed window ends at the first frame when swim speed drops below threshold. Here, the fast_win_ed is the last frame above threshold. Therefore, to get the same swim delay, one extra frame is added.\n",
    "loco_idx_adj['swimDelay'] = loco_idx_adj['swimDelay'] - timedelta(seconds=1/sample_rate)\n",
    "# filter for delays < min_IBI_dur\n",
    "loco_idx_adj = loco_idx_adj.loc[loco_idx_adj['swimDelay'] < timedelta(seconds=min_swim_interval),'locoIDX']\n",
    "# get locomotion indices of the slow windows to adjust\n",
    "loco_idx_adj = loco_idx_adj + 1\n",
    "\n",
    "# create a generater\n",
    "grouped_epoch = iter(grp_by_epoch(spd_window))\n",
    "spd_window_adj = spd_window.copy()\n",
    "# get the first epoch. groupby generator yields both group name and group. Therefore use [1] to get group only\n",
    "current_epoch = pd.DataFrame(next(grouped_epoch)[1])\n",
    "for window_idx in loco_idx_adj:\n",
    "    # advance epoch groups until the current window_idx is within the epoch\n",
    "    while window_idx >= current_epoch['locoIDX'].iloc[-1]:\n",
    "        # get the next epoch. This excludes situation when window_idx equal to the last locoIDX\n",
    "        current_epoch = pd.DataFrame(next(grouped_epoch)[1])\n",
    "    # is the window_idx greater than the first locoIDX in this epoch?\n",
    "    # this excludes situation when window_idx equal to the first locoIDX\n",
    "    if window_idx > current_epoch['locoIDX'].iloc[1]:\n",
    "        spd_window_adj.loc[spd_window_adj['locoIDX'] == window_idx,'swimIndicator'] = 1\n",
    "\n",
    "spd_window_adj = spd_window_adj.assign(\n",
    "    locoIDXadj = spd_window_adj['swimIndicator'].diff().abs().cumsum()\n",
    ")\n",
    "\n",
    "## Alternative way to adjust swim indicators, with the risk of messing up boundaries between epochs\n",
    "# # set their 'swimIndicator' to 1\n",
    "# spd_window.loc[spd_window['locoIDX'].isin(loco_idx_adj),'swimIndicator'] = 1\n",
    "# # re-calculate locomotion index\n",
    "# spd_window = spd_window.assign(\n",
    "#     locoIDXadj = spd_window['swimIndicator'].diff().abs().cumsum()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use code below to visualize the distribution of the length of swim windows before and after adj\n",
    "```\n",
    "ori = spd_window[spd_window.locoIdx % 2 ==1].groupby('locoIdx').size()\n",
    "adj = spd_window[spd_window.locoIdxAdj % 2 ==1].groupby('locoIdxAdj').size()\n",
    "sns.distplot(ori, bins = 15)\n",
    "sns.distplot(adj, bins = 15)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swim direction filter - don't apply for now\n",
    "This filter excludes swims with inconsistant head direction and moving direction, and will drastically change the results (compared to that from the Matlab pipeline).\n",
    "For the swim direction filter, use code below to examine filtered windows:\n",
    "```\n",
    "df_f = grp_by_swim(df,'spdIdx').filter(\n",
    "    lambda g: (\n",
    "        (g['headx'].mean() - g['x'].mean()) * (g.tail(1)['x'].values - g.head(1)['x'].values)\n",
    "    )[0] >= 0\n",
    ")\n",
    "\n",
    "import random\n",
    "tmp2 = df[~df.spd_window.isin(tmp.spd_window)]\n",
    "difflist = list(grp_by_swim(tmp2,'spd_window').size().index)\n",
    "idx = random.sample(difflist,1)\n",
    "sns.lineplot(data = df[df.spd_window.isin(idx)].x, label=\"x\")\n",
    "sns.lineplot(data = df[df.spd_window.isin(idx)].headx, label='head')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate bouts\n",
    "Calculate duration from peak to trough of angular acceleration for each propulsion bout, in a window of 0.6s (+/- 12 samples) surounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the theoretical bout windows based on the peak swim speed\n",
    "\n",
    "# grab the index of the rows with maximun swim speed within each swim window\n",
    "swim_spd_peak_idx = grp_by_swim(spd_window_adj,'locoIDXadj')['swimSpeed'].idxmax()\n",
    "# calculate the starts and ends of bout windows\n",
    "bout_window = pd.concat({\n",
    "    'start':swim_spd_peak_idx-bout_window_half, \n",
    "    'end':swim_spd_peak_idx+bout_window_half, \n",
    "    'peak':swim_spd_peak_idx\n",
    "}, axis=1)\n",
    "\n",
    "# Then, check bout windows for every bouts within each epoch. Assign bout indices for grouping bouts\n",
    "\n",
    "# to avoid the new bout windows from crossing epochs, first, make an epoch generator \n",
    "grouped_epoch = iter(grp_by_epoch(spd_window_adj))\n",
    "# initialize a new dataframe\n",
    "spd_bout_window = pd.DataFrame()\n",
    "# get the first epoch\n",
    "current_epoch = pd.DataFrame(next(grouped_epoch)[1])\n",
    "# loop through bout_window, unpack start, end and peak for convenience\n",
    "for i, (start, end, peak) in bout_window.iterrows():\n",
    "    # for each bout check if it is within the current epoch\n",
    "    if peak > current_epoch.index[-1]:\n",
    "        # if the peak of the bout is out of the current epoch, move to the next epoch\n",
    "        current_epoch = pd.DataFrame(next(grouped_epoch)[1])\n",
    "    # assign a bout index to the new bout window. index = i. start from 0\n",
    "    # bout indices are only assigned to rows within the current epoch\n",
    "    spd_bout_window = spd_bout_window.append(\n",
    "        current_epoch.loc[start:end].assign(boutIDX = i)\n",
    "    )\n",
    "spd_bout_window = spd_bout_window.reset_index(drop=False)\n",
    "\n",
    "# Note, at this point, spd_bout_window has duplicated rows assigned to adjacent bouts because the min_swim_interval is 100 ms but bout windows are 625 ms.\n",
    "# Nevertheless, the number of bouts remain the same\n",
    "if len(spd_bout_window.groupby('boutIDX').size()) == len(grp_by_swim(spd_window_adj,'locoIDXadj').size()):\n",
    "    pass\n",
    "else:\n",
    "    print(\"The number of bouts windows doesn't match the number of speed windows. Program stopped.\")\n",
    "    sys.exit()\n",
    "\n",
    "# # some code for getting peak speed epoch by epoch\n",
    "# tmp = spd_window.copy()\n",
    "# tmp_epoch_gen  = iter(grp_by_epoch(tmp))\n",
    "\n",
    "# tmp_epoch = next(tmp_epoch_gen)[1].reset_index()\n",
    "# tmp_epoch.loc[tmp_epoch['index'].isin(grp_by_swim(spd_window,'locoIDX')['swimSpeed'].idxmax()\n",
    "# )]['swimSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get swim window and bout window indices\n",
    "bout_idx = pd.DataFrame({'boutNum' : (list(range(len(swim_spd_peak_idx))))})\n",
    "bout_idx = bout_idx.assign(\n",
    "    epochNum = df.loc[swim_spd_peak_idx,'epochNum'].values,\n",
    "    peak_idx = swim_spd_peak_idx,\n",
    "    swim_start_idx = grp_by_swim(spd_window_adj,'locoIDXadj').head(1).index,\n",
    "    swim_end_idx = grp_by_swim(spd_window_adj,'locoIDXadj').tail(1).index,\n",
    "    bout_start_idx = spd_bout_window.groupby('boutIDX', as_index=False, sort=False)['index'].head(1).values,\n",
    "    bout_end_idx = spd_bout_window.groupby('boutIDX', as_index=False, sort=False)['index'].tail(1).values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze each bouts for alignment\n",
    "Note: swim duration = 1 frame are excluded\n",
    "\n",
    "```\n",
    " # swim window start/end/time\n",
    "    startTime = grp_by_swim(df, 'swimWindow')['absTime'].head(1).values,\n",
    "    endTime = grp_by_swim(df, 'swimWindow')['absTime'].tail(1).values,\n",
    "res_bouts = res_bouts.assign(\n",
    "    # (SWIM duration + 1 frame)\n",
    "    boutDur = res_bouts['endTime'] + timedelta(seconds=1/sample_rate) - res_bouts['startTime']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    swimWindow = spd_window_adj['locoIDXadj']\n",
    ")\n",
    "# initialize bout attributes\n",
    "bout_attributes = bout_idx.copy()\n",
    "\n",
    "# start and end coordinates of every bout window\n",
    "bout_start_loc = df.loc[bout_idx['bout_start_idx'], ['x','y']]\n",
    "bout_end_loc = df.loc[bout_idx['bout_end_idx'], ['x','y']]\n",
    "\n",
    "# start and end coordinates of every swim window\n",
    "swim_window_loc_diff = df.loc[bout_idx['swim_end_idx'],['x','y']].reset_index(drop=True) - df.loc[bout_idx['swim_start_idx'],['x','y']].reset_index(drop=True)\n",
    "\n",
    "# extract bout attributes\n",
    "bout_attributes = bout_attributes.assign(\n",
    "    # peak swim speed in SWIM windows\n",
    "    peakSpeed = df.loc[swim_spd_peak_idx,'swimSpeed'].values,\n",
    "    # unsmoothed angVel.abs().max() in SWIM windows\n",
    "    maxAbsRawAngVel = grp_by_swim(df, 'swimWindow')['angVel'].apply(\n",
    "        lambda x: np.nanmax(np.absolute(x))), \n",
    "    # unsmoothed peak angVel in SWIM windows\n",
    "    peakRawAngVel = grp_by_swim(df, 'swimWindow')['angVel'].apply(\n",
    "        lambda x: np.nanmax(np.absolute(x)) * (\n",
    "            (np.nanmax(x)+np.nanmin(x)) / np.absolute(np.nanmax(x)+np.nanmin(x))\n",
    "        )\n",
    "    ),\n",
    "    # bout displacement in BOUT windows\n",
    "    propBoutDispl = np.linalg.norm(bout_start_loc.values - bout_end_loc.values, axis=1),\n",
    "    # SWIM window Duration\n",
    "    propBoutDur = grp_by_swim(df, 'swimWindow').apply(len).values/sample_rate,\n",
    "    # cumulative bout heading of SWIM windows in degrees. \n",
    "    # NOTE the swim windows here ends 1 frame earlier than that in the matlab code\n",
    "    IEIheadings = np.degrees(\n",
    "        np.arctan(((swim_window_loc_diff['y'])/(swim_window_loc_diff['x'].abs())).values)\n",
    "    ),\n",
    "    # time with peak swim speed\n",
    "    peakTime = df.loc[swim_spd_peak_idx,'absTime'].values,\n",
    "    # detect if bout is a 'mixed' event with positive and negative angVel over threshold\n",
    "    boutMixedPeak = spd_bout_window.groupby('boutIDX')['angVel'].apply(lambda v: v.abs().max()),\n",
    "    boutMixedIntegral = spd_bout_window.groupby('boutIDX')['angVel'].sum(),\n",
    "    boutMixedValue = lambda x: x['boutMixedPeak']/x['boutMixedIntegral']\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize more attributes\n",
    "bout_attributes = bout_attributes.assign(\n",
    "    if_align = False,\n",
    "    if_align_long = False,\n",
    "    boutInflectAlign = np.nan,\n",
    "    boutAccAlign = np.nan,\n",
    ")    \n",
    "\n",
    "# decide which bouts to \"align\".\n",
    "# if window is far enough from epoch edge to allow alignment & spd during pre/post peak window are sufficiently low\n",
    "# YZ add code to get rid of bouts with only 1 frame above speed threshold\n",
    "for i, bout in bout_idx.iterrows():\n",
    "    # if bouts meet criteria below, if_align = True\n",
    "    if bout['peak_idx'] > (df.loc[df['epochNum']== bout['epochNum']].index.min() + 30) \\\n",
    "    and df.loc[(bout['peak_idx']-10):bout['peak_idx'], 'swimSpeed'].min() < 3 \\\n",
    "    and df.loc[bout['peak_idx']:bout['bout_end_idx'], 'swimSpeed'].min() < 3 \\\n",
    "    and bout['swim_start_idx'] < bout['swim_end_idx']: # added by YZ, get rid of bouts with only 1 frame above speed threshold\n",
    "        # normal alignment, if bout peak far enough from epoch edges\n",
    "        if bout['peak_idx'] < (df.loc[df['epochNum']== bout['epochNum']].index.max() - 20):\n",
    "            bout_attributes.loc[i,'if_align'] = True\n",
    "            # For inflection alignment, find the index of the frame with max speed inflection from boutWindowStart to boutWindowPeak\n",
    "            bout_attributes.loc[i,'boutInflectAlign'] = df.loc[bout['bout_start_idx']:bout['peak_idx'],['swimSpeed']].diff().diff().idxmax().values\n",
    "            # for alignment to max acceleration\n",
    "            # in the Matlab code, since the smooth function doesn't actually smooth the first few values, this index is not accurate \n",
    "            bout_attributes.loc[i,'boutAccAlign'] = smooth_series_ML(df.loc[bout['bout_start_idx']+10:bout['peak_idx'],'swimSpeed'], sm_window).diff().idxmax()\n",
    "    \n",
    "        # get bout number for longer duration alignment (20 extra frames)\n",
    "        if bout['peak_idx'] < (df.loc[df['epochNum']== bout['epochNum']].index.max() - bout_long_tail):\n",
    "            bout_attributes.loc[i,'if_align_long'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract values\n",
    "Unlike the original Matlab code where different values are stored in their own variables, most multi-frame values extracted from all bouts will be stored in one multi-indexed dataframe (bout_res) for convenience. Other 1-value-per-bout data will be stored in another dataframe (bout_res2)\n",
    "\n",
    "Example of bout_res structure:\n",
    "\n",
    "        bout_i    frame_i      col1        col2        col3        col4      \n",
    "        0         0\n",
    "                  1\n",
    "                  2\n",
    "                  ...           \n",
    "        1         0\n",
    "                  1\n",
    "                  2                 \n",
    "                  ...\n",
    "Example of bout_res2 structure:\n",
    "\n",
    "        bout_i    col1        col2        col3        col4      \n",
    "        0           \n",
    "        1\n",
    "        ...     \n",
    "\n",
    "Note: All the acceleration aligned results are skipped & All the bout pairs results are skipped\n",
    "\n",
    "    'propBoutAccAligned_speed'\n",
    "    'propBoutAccAligned_pitch'\n",
    "    PropBoutHeadingPairsFirst\n",
    "    PropBoutHeadingPairsSecond\n",
    "    PropBoutHeadingPairsTime\n",
    "    PropBoutHeadingPairsFirstPitch\n",
    "    PropBoutHeadingPairsFirstAccelerativeRotation\n",
    "    PropBoutHeadingPairsSecondPitch\n",
    "    PropBoutHeadingPairsSecondAccelerativeRotation\n",
    "    PropBoutHeadingPairsSecondPitchRotation\n",
    "    PropBoutHeadingPairsSecondPitchPreBout\n",
    "    PropBoutHeadingPairsIEI\n",
    "    PropBoutHeadingPairsIEIyVel\n",
    "    PropBoutHeadingPairsSecondAlignedPitch\n",
    "    PropBoutHeadingPairsSecondAlignedHeading      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, all the information we need to extract bouts are stored in bout_attributes. Get bouts to align and re_index for upcoming analysis \n",
    "bout_aligned = bout_attributes.loc[bout_attributes['if_align']].reset_index(drop=True)\n",
    "\n",
    "# initialize result dataframe for bout alignment\n",
    "bouts = range(len(bout_aligned))\n",
    "frames = range(51)\n",
    "index = pd.MultiIndex.from_product([bouts, frames], names=['bout_i', 'frame_i'])\n",
    "column = [  'propBoutAligned_angVel_hUp',\n",
    "            'propBoutAligned_angVel_hDn',\n",
    "            'propBoutAligned_speed_hUp',\n",
    "            'propBoutAligned_speed_hDn',\n",
    "            'propBoutAligned_pitch_hUp',\n",
    "            'propBoutAligned_pitch_hDn',\n",
    "            'propBoutAligned_heading',\n",
    "            'propBoutAligned_angVel_flat',\n",
    "            'propBoutAligned_speed_flat',\n",
    "            'propBoutAligned_pitch_flat',\n",
    "        ] \n",
    "bout_res = pd.DataFrame(index=index, columns=column)\n",
    "\n",
    "# set up idx for easy multi-indexing\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# initialize res2 dataframe for 1-per-bout numbers and assign some values\n",
    "bout_res2 = pd.DataFrame()\n",
    "bout_res2 = bout_res2.assign(\n",
    "    aligned_time = df.loc[bout_aligned['peak_idx'], 'absTime'].values,\n",
    "    aligned_time_hUp = np.datetime64('NaT'),\n",
    "    aligned_time_hDn = np.datetime64('NaT'),\n",
    "    # propBoutAligned_time    in the original code is the time in hours\n",
    "    # propBoutAligned_trueTime    in the original code is time in 24hour day elapse\n",
    "    propBoutAligned_dur = bout_aligned['propBoutDur'],     # = swim window duration\n",
    "    propBoutAligned_displ = np.linalg.norm(\n",
    "        df.loc[bout_aligned['peak_idx']+20, ['x','y']].reset_index(drop=True) \\\n",
    "        - df.loc[bout_aligned['peak_idx']-30, ['x','y']].reset_index(drop=True) , \\\n",
    "        axis=1),\n",
    "    propBout_initPitch = np.nan,\n",
    "    propBout_initYPos = np.nan,\n",
    "    propBout_deltaY = np.nan,\n",
    "    propBout_netPitchChg = np.nan,\n",
    "    propBout_matchIndex = bout_aligned['boutNum'],\n",
    "    propBoutIEI_yDispl = np.nan,\n",
    "    propBoutIEI_yDisplTimes = np.nan,\n",
    "    propBoutIEI_yDisplMatchedIEIs = np.nan,\n",
    "    aligned_time_flat = np.nan,\n",
    ")\n",
    "\n",
    "# initialize bout_heading for heading calculation\n",
    "bouts = range(len(bout_aligned))\n",
    "frames = range(51)\n",
    "index = pd.MultiIndex.from_product([bouts, frames], names=['bout_i', 'frame_i'])\n",
    "column = ['xvel_sm', 'yvel_sm']\n",
    "bout_heading = pd.DataFrame(index=index, columns=column)\n",
    "\n",
    "aligned_headUp_counter = 0\n",
    "aligned_headDn_counter = 0\n",
    "aligned_flat_counter = 0\n",
    "\n",
    "# same as before, set up a res2 dataframe for 1-value-per-bout data\n",
    "bout_long_res2 = pd.DataFrame(index=bout_aligned.loc[bout_aligned['if_align_long']].index)\n",
    "\n",
    "bout_matchIndex = bout_aligned.loc[bout_aligned['if_align_long'], 'boutNum']\n",
    "boutAlignLong = bout_aligned.loc[bout_aligned['if_align_long'], 'peak_idx']\n",
    "aligned_timeLong = df.loc[boutAlignLong.values, 'absTime']\n",
    "\n",
    "bout_long_res2 = bout_long_res2.assign(\n",
    "    bout_matchIndex = bout_matchIndex.values,\n",
    "    boutAlignLong = boutAlignLong.values,\n",
    "    alignedLong_time = aligned_timeLong.values,\n",
    "    propBoutLong_initPitch = np.nan,\n",
    "    propBoutLong_initYPos = np.nan,\n",
    "    propBoutLong_netPitchChg = np.nan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align to each epoch\n",
    "bout_res_tmp1 = pd.concat([\n",
    "    df.loc[bout['peak_idx']-30:bout['peak_idx']+20,[  # select rows to concat\n",
    "        'oriIndex',  # select columns to concat\n",
    "        'angVelSmoothed',\n",
    "        'swimSpeed',\n",
    "        'angAccel',\n",
    "        'ang',\n",
    "        'absy',\n",
    "        'x',\n",
    "        'y']\n",
    "    ].assign(bout_i=[i]*51, frame_i=range(51))  # assign bout_i for each bout, assign frame_i for each row  \n",
    "    for i, bout in bout_aligned.iterrows()  # loop through bouts\n",
    "]).set_index(['bout_i','frame_i']).rename(columns={  # reset index\n",
    "        'oriIndex':'oriIndex',\n",
    "        'angVelSmoothed':'propBoutAligned_angVel',\n",
    "        'swimSpeed':'propBoutAligned_speed',\n",
    "        'angAccel':'propBoutAligned_accel',\n",
    "        'ang':'propBoutAligned_pitch',\n",
    "        'absy':'propBoutAligned_absy',\n",
    "        'x':'propBoutAligned_x',\n",
    "        'y':'propBoutAligned_y'\n",
    "})\n",
    "\n",
    "# align to inflection point of speaed (peak of 2nd derivative)\n",
    "bout_res_tmp2 = pd.concat([\n",
    "    df.loc[bout['boutInflectAlign']-30:bout['boutInflectAlign']+20,[\n",
    "        'angVelSmoothed',\n",
    "        'swimSpeed',\n",
    "        'angAccel']\n",
    "    ].assign(bout_i=[i]*51, frame_i=range(51)) \n",
    "    for i, bout in bout_aligned.iterrows()  # loop through bouts\n",
    "    # add a condition for inflect alignment \n",
    "    if bout['boutInflectAlign'] > 30 and bout['boutInflectAlign'] < df.loc[df['epochNum']==bout['epochNum']].index.max()-20\n",
    "]).set_index(['bout_i','frame_i']).rename(columns={\n",
    "    'angVelSmoothed':'propBoutInflAligned_angVel',\n",
    "    'swimSpeed':'propBoutInflAligned_speed',\n",
    "    'angAccel':'propBoutInflAligned_accel'\n",
    "})\n",
    "\n",
    "bout_res = pd.concat([bout_res_tmp1,bout_res_tmp2],axis=1)\n",
    "\n",
    "# long bout tail alignment\n",
    "bout_long_res = pd.concat([\n",
    "    df.loc[bout['peak_idx']-30:bout['peak_idx']+bout_long_tail,[\n",
    "        'angVelSmoothed',\n",
    "        'swimSpeed',\n",
    "        'angAccel',\n",
    "        'ang']\n",
    "    ].assign(bout_i=i, frame_i=range(bout_long_tail+30+1)) \n",
    "    for i, bout in bout_aligned.iterrows() \n",
    "    # add a condition for long bout tail alignment \n",
    "    if bout['if_align_long']\n",
    "]).set_index(['bout_i','frame_i']).rename(columns={\n",
    "    'angVelSmoothed':'propBoutAlignedLong_angVel',\n",
    "    'swimSpeed':'propBoutAlignedLong_speed',\n",
    "    'angAccel':'propBoutAlignedLong_accel',\n",
    "    'ang':'propBoutAlignedLong_pitch'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's do it bout by bout!\n",
    "for i, bout in bout_aligned.iterrows():\n",
    "    aligned_peak = bout['peak_idx']\n",
    "    aligned_start = bout['peak_idx'] - 30\n",
    "    aligned_end = bout['peak_idx'] + 20\n",
    "    # # transfer values with multiple timepoints to bout_res\n",
    "    # # to do this more efficiently, all the bout_res values are acquired with a single pd.concat. See the cell above.\n",
    "    # bout_res.loc[idx[i,:], 'oriIndex'] = df.loc[aligned_start:aligned_end,'oriIndex'].values\n",
    "    # bout_res.loc[idx[i,:], 'propBoutAligned_angVel'] = df.loc[aligned_start:aligned_end,'angVelSmoothed'].values\n",
    "    # bout_res.loc[idx[i,:], 'propBoutAligned_speed'] = df.loc[aligned_start:aligned_end,'swimSpeed'].values\n",
    "    # bout_res.loc[idx[i,:], 'propBoutAligned_accel'] = df.loc[aligned_start:aligned_end,'angAccel'].values\n",
    "    # bout_res.loc[idx[i,:], 'propBoutAligned_pitch'] = df.loc[aligned_start:aligned_end,'ang'].values\n",
    "    # bout_res.loc[idx[i,:], 'propBoutAligned_absy'] = df.loc[aligned_start:aligned_end,'absy'].values\n",
    "    # bout_res.loc[idx[i,:], 'propBoutAligned_x'] = df.loc[aligned_start:aligned_end,'x'].values\n",
    "    # bout_res.loc[idx[i,:], 'propBoutAligned_y'] = df.loc[aligned_start:aligned_end,'y'].values\n",
    "    # put 1-per-bout values into res2\n",
    "    bout_res2.loc[i, 'propBout_initPitch'] = df.loc[aligned_peak-10:aligned_peak-5, 'ang'].mean()\n",
    "    bout_res2.loc[i, 'propBout_initYPos'] = df.loc[aligned_peak-10:aligned_peak-5, 'y'].mean()\n",
    "    bout_res2.loc[i, 'propBout_deltaY'] = df.loc[aligned_peak+5:aligned_peak+10, 'y'].mean() - bout_res2.loc[i, 'propBout_initYPos'] \n",
    "    bout_res2.loc[i, 'propBout_netPitchChg'] = df.loc[aligned_peak+5:aligned_peak+10, 'ang'].mean() - bout_res2.loc[i, 'propBout_initPitch']\n",
    "    # calculate x and y velocity for determining heading\n",
    "    bout_heading.loc[i, 'xvel_sm'] = smooth_ML(df.loc[aligned_start:aligned_end, 'xvel'], sm_window)\n",
    "    bout_heading.loc[i, 'yvel_sm'] = smooth_ML(df.loc[aligned_start:aligned_end, 'yvel'], sm_window)\n",
    "\n",
    "    # if the current (alignable) bout is not the last bout in the epoch \n",
    "    if bout['boutNum'] < bout_attributes.loc[bout_attributes['epochNum']==bout['epochNum'],'boutNum'].max():\n",
    "        swim_start = bout['swim_start_idx']\n",
    "        swim_start_next = bout_attributes.loc[bout['boutNum']+1,'swim_start_idx']\n",
    "        swim_end = bout['swim_end_idx'] + 1  # match swim_end to Matlab code by +1\n",
    "        # and if IEI is long enough\n",
    "        IEI_min = math.ceil(min_swim_interval * sample_rate)  # 4 frames/100ms for 40Hz sample rate\n",
    "        if (swim_start_next-1) - (swim_end+1) > IEI_min:\n",
    "            # get IEI info\n",
    "            bout_res2.loc[i, 'propBoutIEI_yDispl'] = df.loc[swim_start_next-1, 'y'] - df.loc[swim_end+IEI_min,'y']\n",
    "            bout_res2.loc[i, 'propBoutIEI_yDisplTimes'] = bout_res2.loc[i, 'aligned_time']\n",
    "            bout_res2.loc[i, 'propBoutIEI_yDisplMatchedIEIs'] = (swim_start_next - swim_start) / sample_rate\n",
    "\n",
    "    # separate by head up and head down\n",
    "    if bout['peakRawAngVel'] > 0:\n",
    "        aligned_headUp_counter += 1\n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_angVel_hUp'] = bout_res.loc[idx[i,:], 'propBoutAligned_angVel']\n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_speed_hUp'] = bout_res.loc[idx[i,:], 'propBoutAligned_speed'] \n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_pitch_hUp'] = bout_res.loc[idx[i,:], 'propBoutAligned_pitch'] \n",
    "        bout_res2.loc[i, 'aligned_time_hUp'] = bout_res2.loc[i,'aligned_time']\n",
    "    else:\n",
    "        aligned_headDn_counter += 1\n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_angVel_hDn'] = bout_res.loc[idx[i,:], 'propBoutAligned_angVel']\n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_speed_hDn'] = bout_res.loc[idx[i,:], 'propBoutAligned_speed'] \n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_pitch_hDn'] = bout_res.loc[idx[i,:], 'propBoutAligned_pitch'] \n",
    "        bout_res2.loc[i, 'aligned_time_hDn'] = bout_res2.loc[i,'aligned_time']\n",
    "\n",
    "    # collect data for flat bouts: net rotation less than 3 deg\n",
    "    if np.absolute(bout_res2.loc[i, 'propBout_netPitchChg']) <= 3:\n",
    "        aligned_flat_counter += 1\n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_angVel_flat'] = bout_res.loc[idx[i,:], 'propBoutAligned_angVel']\n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_speed_flat'] = bout_res.loc[idx[i,:], 'propBoutAligned_speed'] \n",
    "        bout_res.loc[idx[i,:], 'propBoutAligned_pitch_flat'] = bout_res.loc[idx[i,:], 'propBoutAligned_pitch'] \n",
    "        bout_res2.loc[i, 'aligned_time_flat'] = bout_res2.loc[i,'aligned_time']\n",
    "        \n",
    "    # long bout tail alignment  - see the cell above\n",
    "    if bout['if_align_long']:\n",
    "        bout_long_res2.loc[i,'propBoutLong_initPitch'] = df.loc[aligned_peak-10:aligned_peak-5,'ang'].mean()\n",
    "        bout_long_res2.loc[i,'propBoutLong_initYPos'] = df.loc[aligned_peak-10:aligned_peak-5,'y'].mean()\n",
    "        bout_long_res2.loc[i,'propBoutLong_netPitchChg'] = df.loc[aligned_peak+5:aligned_peak+10,'ang'].mean() - bout_res2.loc[i, 'propBout_initPitch']\n",
    "    #     bout_long_res.loc[idx[j,:], 'propBoutAlignedLong_angVel'] = df.loc[aligned_start:alignedLong_end,'angVelSmoothed'].values\n",
    "    #     bout_long_res.loc[idx[j,:], 'propBoutAlignedLong_speed'] = df.loc[aligned_start:alignedLong_end,'swimSpeed'].values\n",
    "    #     bout_long_res.loc[idx[j,:], 'propBoutAlignedLong_accel'] = df.loc[aligned_start:alignedLong_end,'angAccel'].values\n",
    "    #     bout_long_res.loc[idx[j,:], 'propBoutAlignedLong_pitch'] = df.loc[aligned_start:alignedLong_end,'ang'].values\n",
    "    #     j += 1\n",
    "    # align for mixed bouts at two thresholds (skipped)\n",
    "\n",
    "    # # align to inflection point of speaed (peak of 2nd derivative)  - see the cell above\n",
    "    # if bout['boutInflectAlign'] > 30 and bout['boutInflectAlign'] < df.loc[df['epochNum']==bout['epochNum']].index.max() - 20:\n",
    "    #     inflectAlign_start = bout['boutInflectAlign'] - 30\n",
    "    #     inflectAlign_end = bout['boutInflectAlign'] + 20\n",
    "    #     bout_res.loc[idx[i,:], 'propBoutInflAligned_angVel'] = df.loc[inflectAlign_start:inflectAlign_end,'angVelSmoothed'].values\n",
    "    #     bout_res.loc[idx[i,:], 'propBoutInflAligned_speed'] = df.loc[inflectAlign_start:inflectAlign_end,'swimSpeed'].values\n",
    "    #     bout_res.loc[idx[i,:], 'propBoutInflAligned_accel'] = df.loc[inflectAlign_start:inflectAlign_end,'angAccel'].values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the heading in -180:180 deg, which is the same unit/range as the original PropBoutAlignedHeading after U_D/R_L modifications\n",
    "bout_res = bout_res.assign(\n",
    "    propBoutAligned_heading = np.degrees(np.arctan2(bout_heading['xvel_sm'].values.astype(float), bout_heading['yvel_sm'].values.astype(float)))\n",
    ")\n",
    "\n",
    "# x and y displacement for bout trajectory calculation\n",
    "yy = (bout_res.loc[idx[:,35],'propBoutAligned_y'].values - bout_res.loc[idx[:,26],'propBoutAligned_y'].values).astype(float)\n",
    "absxx = np.absolute((bout_res.loc[idx[:,35],'propBoutAligned_x'].values - bout_res.loc[idx[:,26],'propBoutAligned_x'].values)).astype(float)\n",
    "\n",
    "# get more data\n",
    "bout_res2 = bout_res2.assign(\n",
    "    epochBouts_indices = bout_aligned['peak_idx'],\n",
    "    epochBouts_heading = bout_res.loc[idx[:,30],'propBoutAligned_heading'].values,\n",
    "    epochBouts_preBoutPitch = bout_res.loc[idx[:,26],'propBoutAligned_pitch'].values,\n",
    "    epochBouts_earlyRotations_28_30 = bout_res.loc[idx[:,29],'propBoutAligned_pitch'].values - bout_res.loc[idx[:,27],'propBoutAligned_pitch'].values,\n",
    "    epochBouts_earlyRotations = bout_res.loc[idx[:,30],'propBoutAligned_pitch'].values - bout_res.loc[idx[:,27],'propBoutAligned_pitch'].values,\n",
    "    epochBouts_lateRotations = bout_res.loc[idx[:,34],'propBoutAligned_pitch'].values - bout_res.loc[idx[:,31],'propBoutAligned_pitch'].values,\n",
    "    epochBouts_trajectory = np.degrees(np.arctan(yy/absxx))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get/rename values from ALL bouts\n",
    "bout_attributes = bout_attributes.rename(columns={'peakTime':'propBout_time',\n",
    "                                'peakSpeed':'propBout_maxSpd',\n",
    "                                'maxAbsRawAngVel':'propBout_maxAngvel',\n",
    "                                'propBoutMixedIntegral':'propBoutMixed_integral',\n",
    "                                'boutMixedPeak':'propBoutMixed_peak',\n",
    "                                'boutMixedValue':'propBoutMixed_value',\n",
    "                                'peakRawAngVel':'propBout_peakAngvel',\n",
    "                                })\n",
    "# get fish length\n",
    "# bout_attributes = pd.merge(bout_attributes, fish_length, how='left', on='epochNum')\n",
    "bout_attributes = bout_attributes.assign(\n",
    "    fisn_length = bout_attributes['epochNum'].map(fish_length.set_index('epochNum').to_dict()['fishLenEst'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract IEI values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate corresponding pitch and angular velocity for IEIs. include window from SpdWindEnd to next SpdWindStart padded with 0.1s\n",
    "# differs from IEI detection and PropBout BoutWindows)\n",
    "post_peak_buf = math.ceil(0.3 * sample_rate)\n",
    "pre_peak_buf = math.ceil(0.1 * sample_rate)\n",
    "IEI_2_swim_buf = math.ceil(0.05 * sample_rate)\n",
    "IEI_tail = 30  # frames\n",
    "\n",
    "# Initialize IEI attributes \n",
    "IEI_attributes = bout_attributes[['boutNum','epochNum','swim_start_idx','swim_end_idx']]\n",
    "IEI_attributes = IEI_attributes.assign(\n",
    "    # shift the end of each bout down by 1 row for easy iteration\n",
    "    # NOTE: the swim_end indices here are 1 idx smaller than that in Matlab\n",
    "    swim_end_shift = pd.concat([pd.DataFrame({'swim_end_idx':np.nan}, index=[0]), bout_attributes[['swim_end_idx']]]).reset_index(drop = True)\n",
    ")\n",
    "\n",
    "# Initialize res2\n",
    "IEI_res2 = bout_attributes[['boutNum','epochNum']]\n",
    "IEI_res2 = IEI_res2.assign(\n",
    "    propBoutIEI = grp_by_epoch(bout_attributes)['swim_start_idx'].diff()/sample_rate,\n",
    "    propBoutIEItime = bout_attributes.loc[grp_by_epoch(bout_attributes).cumcount() >= 1, 'propBout_time'],\n",
    "    # ignore PropBoutIEItrueTime\n",
    ")\n",
    "\n",
    "# drop first row of each epoch (rows with NA)\n",
    "rows_to_drop = list(IEI_res2.loc[IEI_res2['propBoutIEItime'].isna()].index)\n",
    "IEI_attributes.drop(rows_to_drop, inplace=True)\n",
    "IEI_res2.drop(rows_to_drop, inplace=True)\n",
    "# all swim_end_shift and swim_start in the same row belong to the same epoch\n",
    "# reset index\n",
    "IEI_attributes = IEI_attributes.reset_index(drop=True)\n",
    "IEI_res2 = IEI_res2.reset_index(drop=True)\n",
    "# get some values\n",
    "IEI_res2 = IEI_res2.assign(\n",
    "    # again, when using swim_end as an index, +1 to match the idx to Matlab\n",
    "    propBoutIEI_pitchFirst = df.loc[IEI_attributes['swim_end_shift']+1+post_bout_buf, 'ang'].values,\n",
    "    propBoutIEI_pitchLast = df.loc[IEI_attributes['swim_start_idx']-IEI_2_swim_buf, 'ang'].values,\n",
    "    # use smoothed angVel for post bout vel\n",
    "    propBoutIEI_angVel_postBout = df.loc[IEI_attributes['swim_end_shift']+1+post_bout_buf, 'angVelSmoothed'].values,\n",
    "    propBoutIEI_angVel_preNextBout = df.loc[IEI_attributes['swim_start_idx']-IEI_2_swim_buf, 'angVelSmoothed'].values,\n",
    "    # Other values to calculate\n",
    "    propBoutIEI_pitch = np.nan,\n",
    "    propBoutIEI_angVel = np.nan,\n",
    "    propBoutIEI_angAcc = np.nan,\n",
    "    propBoutIEI_pauseDur = np.nan,\n",
    "    propBoutIEI_yvel = np.nan,\n",
    "    IEI_matchIndex = np.nan,\n",
    "    rowsInRes = np.nan,\n",
    "    propBoutIEI_heading = np.nan,\n",
    ")\n",
    "\n",
    "# initialize res3 for timed IEI results (multi-indexed)\n",
    "IEI = range(len(IEI_attributes))\n",
    "frames = range(IEI_tail)\n",
    "index = pd.MultiIndex.from_product([IEI, frames], names=['IEI_i', 'frame_i'])\n",
    "column = [  'propBoutIEI_timedHeading',\n",
    "            'propBoutIEI_timedPitch',\n",
    "            'propBoutIEI_timedHeadingPre',\n",
    "            'propBoutIEI_timedPitchPre',\n",
    "        ] \n",
    "IEI_res3 = pd.DataFrame(index=index, columns=column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "for i, row in IEI_attributes.iterrows():\n",
    "    # get some index calculation done \n",
    "    bout_end_post = row['swim_end_shift'] + 1 + post_bout_buf  # where last bout ends. to match the swim end in Matlab, +1\n",
    "    bout_start_pre = row['swim_start_idx'] - IEI_2_swim_buf  # where next bout starts\n",
    "    bout_end_5frames = row['swim_end_shift'] + 1 + math.ceil(0.05*sample_rate)  # why use 0.05 but not post_bout_buf for duration calculation???????\n",
    "    bout_start_4frames = row['swim_start_idx'] - pre_bout_buf\n",
    "    # assign values. NOTE: smoothed results are used for angVel and angAccel\n",
    "    IEI_res2.loc[i,'propBoutIEI_pitch'] = df.loc[bout_end_post:bout_start_pre,'ang'].mean()\n",
    "    IEI_res2.loc[i,'propBoutIEI_angVel'] = df.loc[bout_end_post:bout_start_pre,'angVelSmoothed'].mean()\n",
    "    IEI_res2.loc[i,'propBoutIEI_angAcc'] = df.loc[bout_end_post:bout_start_4frames,'angVelSmoothed'].diff().mean()\n",
    "    IEI_res2.loc[i,'propBoutIEI_pauseDur'] = (bout_start_4frames - bout_end_5frames) / sample_rate\n",
    "    # why use 0.3 but not post_bout_buf for yvel???????????\n",
    "    IEI_res2.loc[i,'propBoutIEI_yvel'] = df.loc[row['swim_end_shift']+1+math.ceil(0.3*sample_rate):bout_start_4frames, 'yvel'].mean()\n",
    "    IEI_res2.loc[i,'IEI_matchIndex'] = i\n",
    "    IEI_res2.loc[i,'rowsInRes'] = bout_start_4frames - bout_end_5frames + 1\n",
    "    # is IEI long enough?\n",
    "    if row['swim_start_idx']-(row['swim_end_shift']+1) < IEI_tail:\n",
    "        # if not\n",
    "        IEI_res3.loc[idx[i,:],['propBoutIEI_timedHeading','propBoutIEI_timedPitch','propBoutIEI_timedHeadingPre','propBoutIEI_timedPitchPre']] = 500\n",
    "    else:\n",
    "        # if yes\n",
    "        swim_end = row['swim_end_shift'] + 1\n",
    "        swim_start = row['swim_start_idx']\n",
    "        # NOTE: headings below are different from the Matlab code. X differences are not abs()\n",
    "        # heading\n",
    "        IEI_res2.loc[i,'propBoutIEI_heading'] = np.degrees(np.arctan(\n",
    "            (df.loc[swim_start,'y'] - df.loc[swim_end,'y'])\n",
    "            / np.absolute(df.loc[swim_start,'x'] - df.loc[swim_end,'x'])\n",
    "            ))\n",
    "        # timed heading and heading pre\n",
    "        if df.loc[swim_end+IEI_tail, 'epochNum'] == row['epochNum']:\n",
    "            # if there's enough rows in the current epoch for getting (swim_end + IEI_tail)\n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedHeading'] = np.degrees(np.arctan(\n",
    "                (df.loc[swim_end:swim_end+IEI_tail,'y'].diff().dropna().values)  # because of diff(), first value is na\n",
    "                / (df.loc[swim_end:swim_end+IEI_tail,'x'].diff().abs().dropna().values)  # use abs() to get rid of x directionality\n",
    "            ))\n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedPitch'] = df.loc[swim_end:swim_end+IEI_tail-1,'ang'].values\n",
    "        else: \n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedHeading'] = 500\n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedPitch'] = 500\n",
    "\n",
    "        if df.loc[swim_start-IEI_tail, 'epochNum'] == row['epochNum']:\n",
    "            # if there's enough rows in the current epoch for getting (swim_start - IEI_tail)\n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedHeadingPre'] = np.degrees(np.arctan(\n",
    "                (df.loc[swim_start-IEI_tail:swim_start,'y'].diff().dropna().values) \n",
    "                / (df.loc[swim_start-IEI_tail:swim_start,'x'].diff().abs().dropna().values)\n",
    "            ))     \n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedPitchPre'] = df.loc[swim_start-IEI_tail+1:swim_start,'ang'].values\n",
    "        else:\n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedHeadingPre'] = 500\n",
    "            IEI_res3.loc[idx[i,:],'propBoutIEI_timedPitchPre'] = 500\n",
    "\n",
    "# for aligned values (multiple values for each IEI), use pd.concat (which is more efficient)\n",
    "IEI_res = pd.concat([\n",
    "    df.loc[(\n",
    "        IEI_attributes.loc[i,'swim_end_shift']+1+math.ceil(0.05*sample_rate)  # bout_end_5frames\n",
    "    ):(\n",
    "        IEI_attributes.loc[i,'swim_start_idx']-pre_bout_buf  # bout_start_4frames\n",
    "    ),['angVelSmoothed','ang','yvel']] for i in range(len(IEI_attributes)  # get these values for each IEI\n",
    ")], ignore_index=True)\n",
    "\n",
    "IEI_res = IEI_res.rename(columns = {'angVelSmoothed':'propBoutIEIAligned_angVel',\n",
    "                                   'ang':'propBoutIEIAligned_pitch',\n",
    "                                   'yvel':'propBoutIEIAligned_yvel'})\n",
    "\n",
    "# find matching IEI, pre-IEI pitch and post-IEI net rotation\n",
    "IEI_wolpert = pd.DataFrame({\n",
    "    # wolpert values starts from the second IEI, thus exclude the first IEI match index\n",
    "    'IEI_matchIndex': IEI_res2.loc[1:,'IEI_matchIndex'].tolist(),\n",
    "    # only get the pre IEI value, exclude the last speed_window_start.diff(). Be aware that df.loc[a:b] includes both a and b \n",
    "    'wolpert_IEI': IEI_res2.loc[:len(IEI_res2)-2,'propBoutIEI'].tolist(),\n",
    "    # same as above, exclude the last pitch\n",
    "    'wolpert_preIEI_pitch': IEI_res2.loc[:len(IEI_res2)-2,'propBoutIEI_pitchFirst'].tolist(),\n",
    "    'wolpert_postIEI_netRot': (IEI_res2.loc[1:,'propBoutIEI_pitchFirst'].values - IEI_res2.loc[:len(IEI_res2)-2,'propBoutIEI_pitchLast'].values).tolist(),\n",
    "    'wolpert_Time': IEI_res2.loc[1:,'propBoutIEItime'].tolist()\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acqure epoch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_attributes = pd.DataFrame(index=range(len(grp_by_epoch(df).size())))\n",
    "# epoch_attributes = pd.DataFrame(index=range(len(grp_by_epoch(df).size())))\n",
    "grouped_df = grp_by_epoch(df)\n",
    "# get angular vel at baseline speed. store separately. TO SAVE\n",
    "all_baseline_angVel = df.loc[df['swimSpeed']<BASELINE_THRESHOLD,['angVel','epochNum']]\n",
    "# get average of angvel per epoch\n",
    "epoch_attributes = pd.DataFrame(index=range(len(grouped_df.size())))\n",
    "epoch_attributes = epoch_attributes.assign(\n",
    "    mean_bl_angVel = grp_by_epoch(all_baseline_angVel)[['angVel']].mean(),\n",
    "    epoch_absTime = grouped_df.head(1)['absTime'].values,\n",
    "    epoch_mean_angVel = grouped_df['angVel'].mean(),\n",
    "    # why use velocity????? shouldn't be using swimSpeed??????\n",
    "    # YZ 2020.5.27 change to swimSpeed\n",
    "    epoch_pause_yvel = grouped_df.apply(lambda e: e.loc[e['swimSpeed']<BASELINE_THRESHOLD,'yvel'].mean()),\n",
    "    epoch_bout_yvel = grouped_df.apply(lambda e: e.loc[e['swimSpeed']>PROPULSION_THRESHOLD,'yvel'].mean()),\n",
    "    x_dir = grouped_df.apply(lambda e: e.loc[e['swimSpeed']>PROPULSION_THRESHOLD,'yvel'].mean()),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab all headings (movement angles)\n",
    "```\n",
    "for: each epoch\n",
    "    if: x[-1] > x[1]  # >> \n",
    "        then: move_angle = np.arctan2(yvel,xvel)\n",
    "    if: x[-1] < x[1]  # <<\n",
    "        then: flip x axis\n",
    "              move_angle = np.arctan2(yvel,-xvel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chopped = df.assign(\n",
    "    # because sm_window = 3 and the first vel of each epoch is NA\n",
    "    # and NA values caused by smoothing will be dropped later, smooth through all the rows won't cause epoch-crossing troubles\n",
    "    xvel_sm = smooth_series_ML(df['xvel'],sm_window),\n",
    "    yvel_sm = smooth_series_ML(df['yvel'],sm_window),\n",
    "    # also get an x axis modifier, +1 to right, -1 to left\n",
    "    x_dir = grouped_df['x'].transform(\n",
    "        lambda x: (x.iloc[-1] - x.iloc[0])/np.absolute(x.iloc[-1] - x.iloc[0])\n",
    "    )\n",
    ")\n",
    "# chop top and bottom rows\n",
    "rows_to_drop = grouped_df.head(edge_chop).index.to_list() + grouped_df.tail(edge_chop).index.to_list()\n",
    "df_chopped.drop(axis=0, index=rows_to_drop, inplace=True)\n",
    "df_chopped = df_chopped.reset_index(drop=False)\n",
    "df_chopped.rename(columns={'index':'dfIdx'}, inplace=True)\n",
    "heading_res = df_chopped[['dfIdx','epochNum']]\n",
    "# now we can calculate move angles\n",
    "heading_res = heading_res.assign(\n",
    "    moveAngle = np.degrees(np.arctan2(\n",
    "        df_chopped['yvel_sm'], (df_chopped['xvel_sm']*df_chopped['x_dir'])\n",
    "    )),\n",
    "    # get other data that match up with headings\n",
    "    headingMatched_ang = df_chopped['ang'],\n",
    "    headingMatched_speed = df_chopped['swimSpeed'],\n",
    "    headingMatched_angVel = df_chopped['angVel'],\n",
    "    headingMatched_angAccel = df_chopped['angAccel'],\n",
    "    headingMathced_time = df_chopped['absTime'],\n",
    "    headingMatched_yvel = df_chopped['yvel_sm']\n",
    ")\n",
    "# calculate mean pitch and heading for epoch, and RMSpitch (line ~770 in Matlab)\n",
    "heading_res2 = grp_by_epoch(heading_res)[['headingMatched_ang','moveAngle']].mean()\n",
    "heading_res2 = heading_res2.rename(columns={'headingMatched_ang':'epochPitch','moveAngle':'epochHeading'})\n",
    "# calculate RMS, NOTE I don't understand why the RMS is calculated in the way below, but this is the code from Matlab\n",
    "heading_res2 = heading_res2.assign(\n",
    "    # in deg/sec\n",
    "    RMS_pitch = grp_by_epoch(df_chopped)['centeredAng'].apply(\n",
    "        lambda x: np.sqrt(np.sum(x**2))/len(x)*sample_rate\n",
    "    ),\n",
    "    # in mm/(sec^2)\n",
    "    RMS_speed = grp_by_epoch(df_chopped)['velocity'].apply(\n",
    "        lambda x: np.sqrt(np.sum(x**2))/len(x)*sample_rate\n",
    "    )   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'bout_attributes': ['boutNum',\n  'epochNum',\n  'peak_idx',\n  'swim_start_idx',\n  'swim_end_idx',\n  'bout_start_idx',\n  'bout_end_idx',\n  'propBout_maxSpd',\n  'propBout_maxAngvel',\n  'propBout_peakAngvel',\n  'propBoutDispl',\n  'propBoutDur',\n  'IEIheadings',\n  'propBout_time',\n  'propBoutMixed_peak',\n  'boutMixedIntegral',\n  'propBoutMixed_value',\n  'if_align',\n  'if_align_long',\n  'boutInflectAlign',\n  'boutAccAlign',\n  'fisn_length']}"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "{'bout_attributes':bout_attributes.columns.to_list()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Variables! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = f\"{file_path}/data/\"\n",
    "\n",
    "# # ['boutNum', 'epochNum', 'peak_idx', 'swim_start_idx', 'swim_end_idx', 'bout_start_idx', 'bout_end_idx', 'propBout_maxSpd', 'propBout_maxAngvel', 'propBout_peakAngvel', 'propBoutDispl', 'propBoutDur', 'IEIheadings', 'propBout_time', 'propBoutMixed_peak', 'boutMixedIntegral', 'propBoutMixed_value', 'if_align', 'if_align_long', 'boutInflectAlign', 'boutAccAlign', 'fisn_length']\n",
    "# bout_attributes.to_pickle(f'{file_path}/data/boutAttributes.pkl')\n",
    "\n",
    "# # ['oriIndex', 'propBoutAligned_angVel', 'propBoutAligned_angVel_hUp', 'propBoutAligned_angVel_hDn', 'propBoutAligned_speed', 'propBoutAligned_speed_hUp', 'propBoutAligned_speed_hDn', 'propBoutAligned_accel', 'propBoutAligned_pitch', 'propBoutAligned_pitch_hUp', 'propBoutAligned_pitch_hDn', 'propBoutAligned_absy', 'propBoutAligned_x', 'propBoutAligned_y', 'propBoutAligned_heading', 'propBoutAligned_angVel_flat', 'propBoutAligned_speed_flat', 'propBoutAligned_pitch_flat', 'propBoutInflAligned_angVel', 'propBoutInflAligned_speed', 'propBoutInflAligned_accel']\n",
    "# bout_res.to_pickle(f'{file_path}/data/propBoutAligned.pkl')\n",
    "\n",
    "# # ['aligned_time', 'aligned_time_hUp', 'aligned_time_hDn', 'propBoutAligned_dur', 'propBoutAligned_displ', 'propBout_initPitch', 'propBout_initYPos', 'propBout_deltaY', 'propBout_netPitchChg', 'propBout_matchIndex', 'propBoutIEI_yDispl', 'propBoutIEI_yDisplTimes', 'propBoutIEI_yDisplMatchedIEIs', 'aligned_time_flat', 'epochBouts_indices', 'epochBouts_heading', 'epochBouts_preBoutPitch', 'epochBouts_earlyRotations_28_30', 'epochBouts_earlyRotations', 'epochBouts_lateRotations', 'epochBouts_trajectory']\n",
    "# bout_res2.to_pickle(f'{file_path}/data/propBout2.pkl')\n",
    "\n",
    "# # ['propBoutAlignedLong_angVel', 'propBoutAlignedLong_speed', 'propBoutAlignedLong_accel', 'propBoutAlignedLong_pitch']\n",
    "# bout_long_res.to_pickle(f'{file_path}/data/propBoutAlignedLong.pkl')\n",
    "\n",
    "# # ['propBoutAlignedLong_angVel', 'propBoutAlignedLong_speed', 'propBoutAlignedLong_accel', 'propBoutAlignedLong_pitch']\n",
    "# bout_long_res2.to_pickle(f'{file_path}/data/propBoutAlignedLong2.pkl')\n",
    "\n",
    "# # ['boutNum', 'epochNum', 'swim_start_idx', 'swim_end_idx', 'swim_end_shift']\n",
    "# IEI_attributes.to_pickle(f'{file_path}/data/IEIAttributes.pkl')\n",
    "\n",
    "# # ['propBoutIEIAligned_angVel', 'propBoutIEIAligned_pitch', 'propBoutIEIAligned_yvel']\n",
    "# IEI_res.to_pickle(f'{file_path}/data/propBoutIEIAligned.pkl')\n",
    "\n",
    "# # ['boutNum', 'epochNum', 'propBoutIEI', 'propBoutIEItime', 'propBoutIEI_pitchFirst', 'propBoutIEI_pitchLast', 'propBoutIEI_angVel_postBout', 'propBoutIEI_angVel_preNextBout', 'propBoutIEI_pitch', 'propBoutIEI_angVel', 'propBoutIEI_angAcc', 'propBoutIEI_pauseDur', 'propBoutIEI_yvel', 'IEI_matchIndex', 'rowsInRes', 'propBoutIEI_heading']\n",
    "# IEI_res2.to_pickle(f'{file_path}/data/{file_i+1}_propBoutIEI.pkl')\n",
    "\n",
    "# # ['propBoutIEI_timedHeading', 'propBoutIEI_timedPitch', 'propBoutIEI_timedHeadingPre', 'propBoutIEI_timedPitchPre']\n",
    "# IEI_res3.to_pickle(f'{file_path}/data/{file_i+1}_propBoutIEItimed.pkl')\n",
    "\n",
    "# # ['IEI_matchIndex', 'wolpert_IEI', 'wolpert_preIEI_pitch', 'wolpert_postIEI_netRot', 'wolpert_Time']\n",
    "# IEI_wolpert.to_pickle(f'{file_path}/data/{file_i+1}_wolpertIEI.pkl')\n",
    "\n",
    "# # ['epochNum', 'mean_bl_angVel', 'epoch_absTime', 'epoch_mean_angVel', 'epoch_pause_yvel', 'epoch_bout_yvel', 'x_dir']\n",
    "# epoch_attributes.to_pickle(f'{file_path}/data/{file_i+1}_epochAttributes.pkl')\n",
    "\n",
    "# # ['dfIdx', 'epochNum', 'moveAngle', 'headingMatched_ang', 'headingMatched_speed', 'headingMatched_angVel', 'headingMatched_angAccel', 'headingMathced_time', 'headingMatched_yvel']\n",
    "# heading_res.to_pickle(f'{file_path}/data/{file_i+1}_headingMatched.pkl')\n",
    "\n",
    "# # ['epochPitch', 'epochHeading', 'RMS_pitch', 'RMS_speed']\n",
    "# heading_res2.to_pickle(f'{file_path}/data/{file_i+1}_epochPitchHeading_RMS.pkl')\n",
    "\n",
    "# print (f\"File {file_i+1}: variables successfully saved! \\n__\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bityzvfconda5c003cd747b248a28de2ce1a07e29099",
   "display_name": "Python 3.8.2 64-bit ('YZVF': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}