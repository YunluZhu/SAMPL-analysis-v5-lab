{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Free Vertical\n",
    "- Includes: \n",
    "    1. analyzeFreeVerticalGrouped2\n",
    "    2. some filters in GrabFishAngelAll (angular acceleration)\n",
    "\n",
    "- Purpose of Python version by YZ:\n",
    "    1. Rewrite of analyzeFreeVerticalGrouped2.m & GrabFishAngleAll.m for faster runtime (5s per .dlm)\n",
    "    3. Adjust filters\n",
    "\n",
    "- Notes:\n",
    "    1. Results of filtered epochs may be slightly different from Matlab results, due to the angVel smooth function\n",
    "        Matlab smooth handles top/end values differently.\n",
    "    2. Due to the float64 data type, calculations are more accurate in the Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules and functions\n",
    "import pandas as pd
from plot_functions.plt_tools import round_half_up \n",
    "import numpy as np # numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import itertools \n",
    "import os,glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def grp_by_epoch(df):\n",
    "    '''Group df by 'epochNum'. If cols is empty take all columns'''\n",
    "    return df.groupby('epochNum', sort=False)\n",
    "\n",
    "# def smooth(y, box_pts):\n",
    "#     '''\n",
    "#     smooth data using convolution\n",
    "#     different from MATLAB version, does not handle beginning and end well\n",
    "#     '''\n",
    "#     box = np.ones(box_pts)/box_pts\n",
    "#     y_smooth = np.convolve(y.values, box, mode='same')\n",
    "#     return y_smooth\n",
    "\n",
    "def smooth_series_ML(a,WSZ):\n",
    "    '''\n",
    "    Modified from Divakar's answer https://stackoverflow.com/questions/40443020/matlabs-smooth-implementation-n-point-moving-average-in-numpy-python\n",
    "    a: NumPy 1-D array containing the data to be smoothed\n",
    "    WSZ: smoothing window size needs, which must be odd number,\n",
    "    as in the original MATLAB implementation\n",
    "    '''\n",
    "    out0 = np.convolve(a,np.ones(WSZ,dtype=int),'valid')/WSZ    \n",
    "    r = np.arange(1,WSZ-1,2)\n",
    "    start = np.cumsum(a[:WSZ-1])[::2]/r\n",
    "    stop = (np.cumsum(a[:-WSZ:-1])[::2]/r)[::-1]\n",
    "    res = np.concatenate((  start , out0, stop  ))\n",
    "    return pd.Series(data=res, index=a.index)\n",
    "\n",
    "# define filter function\n",
    "def raw_filter(df):\n",
    "    '''Trim epoch by epoch_buf and filter by duration & fish number'''\n",
    "    # First, group by epoch number\n",
    "    grouped = grp_by_epoch(df)\n",
    "    # Truncate epoch, see epoch_buf for details\n",
    "    # use .cumcount() to return indices within group\n",
    "    del_buf = df[(grouped.cumcount(ascending=False) >= epoch_buf) \n",
    "        & (grouped.cumcount() >= epoch_buf)]\n",
    "    # Flter by epoch duration & number of fish in the frame\n",
    "    filtered = grp_by_epoch(del_buf).filter(\n",
    "        lambda g: len(g) >= min_dur and \n",
    "        np.nanmax(g['fishNum'].values) < max_fish\n",
    "    )\n",
    "    print(\".\")\n",
    "    return filtered\n",
    "\n",
    "def dur_y_x_filter(df):\n",
    "    # drop epochs with inexplicably large gaps between frame\n",
    "    f1 = grp_by_epoch(df).filter(\n",
    "        lambda g: np.nanmax(g['deltaT'].values) <= max_delta_t\n",
    "    # turned off in Kyla's version\n",
    "    #     # exclude fish bouts vertically down (sinking faster than 5mm/sec). \n",
    "    #     # Flip the sign so positive deltaY corresponds to upward motion\n",
    "    #     and -(np.nanmax(np.diff(g['y'].values, prepend=g['y'].values[0]))) > min_verticle_vel * frame_interval * scale\n",
    "    )\n",
    "    # only keep swims in which fish is pointed in the direction it moves. Within an epoch, if headx is greater than x (pointing right), x.tail should also be greater than x.head, and vice versa.\n",
    "    f2 = grp_by_epoch(f1).filter(\n",
    "        lambda g: ((g['headx'].mean() - g['x'].mean()) * g.tail(1)['x'].values)[0] >= 0\n",
    "    )\n",
    "    print(\".\")\n",
    "    return f2\n",
    "\n",
    "\n",
    "def displ_dist_vel_filter(df):\n",
    "    # drop epochs with improbably large instantaneous displacement, which happens where #fish > 1 but appear as 1 fish\n",
    "    f1 = grp_by_epoch(df).filter(\n",
    "        lambda g: np.nanmax(np.absolute(g['displ'].values)) <= max_inst_displ\n",
    "        # exclude epochs with sudden & large instantaneous movement (distance). Found in ~1-2 epochs per .dlm after max_inst_displ filtration - YZ 2020.05.13\n",
    "        # turn off vor now\n",
    "        and np.nanmax(np.abs(\n",
    "            g['dist'].values - g['dist'].rolling(3, center=True).median().values\n",
    "        )) < max_dist_travel   \n",
    "    )\n",
    "    # exclude epochs with improbably large angular velocity. use smoothed results\n",
    "\n",
    "    f2 = grp_by_epoch(f1).filter(\n",
    "        lambda g: np.nanmax(np.abs(\n",
    "            smooth_series_ML(g.loc[1:,'angVel'], sm_window_for_filter).values\n",
    "        )) <= max_angle_vel\n",
    "    )\n",
    "  \n",
    "\n",
    "    # exclude epochs with improbably large angular accel. numpy calculation is faster\n",
    "    f3 = grp_by_epoch(f2).filter(\n",
    "        lambda g: np.nanmax(np.abs(g['angAccel'].values)) <= max_angle_accel\n",
    "    )\n",
    "    print(\".\")\n",
    "    return f3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def displ_DEE_vel_filter(df):\n",
    "#     # drop epochs with improbably large instantaneous displacement, which happens where #fish > 1 but appear as 1 fish\n",
    "#     f1 = grp_by_epoch(df).filter(\n",
    "#         lambda g: np.nanmax(g['displ_DEE'].values) <= max_inst_displ\n",
    "#         # exclude epochs with sudden & large displacement. Found in ~1-2 epochs per .dlm after max_inst_displ filtration - YZ 2020.05.13\n",
    "#         # and np.nanmax(np.abs(\n",
    "#         #     g['displ'].values - g['displ'].rolling(3, center=True).median().values\n",
    "#         # )) < max_adj_displ_diff   \n",
    "#     )\n",
    "#     # exclude epochs with improbably large angular velocity. use smoothed results\n",
    "#     f2 = grp_by_epoch(f1).filter(\n",
    "#         lambda g: np.nanmax(np.abs(\n",
    "#             smooth(g['angVel'], sm_window_for_filter)\n",
    "#         )) <= max_angle_vel\n",
    "#     )\n",
    "#     # exclude epochs with improbably large angular accel. numpy calculation is faster\n",
    "#     f3 = grp_by_epoch(f2).filter(\n",
    "#         lambda g: np.nanmax(np.abs(g['angAccel'].values)) <= max_angle_accel\n",
    "#     )\n",
    "#     print(\".\")\n",
    "#     return f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "frame_rate = 40      # Hz\n",
    "frame_interval = 1/frame_rate\n",
    "\n",
    "min_dur = 100        # all epochs that are too short\n",
    "max_fish = 1         # all epochs that have more than one fish\n",
    "max_inst_displ = 35  # epochs where fish# > 1 but appear as 1 fish will have improbably large instantaneous displacement.\n",
    "max_angle_vel = 100  # or an improbably large angular velocity\n",
    "max_angle_accel = 32000  # or an improbably large angular accel.\n",
    "max_delta_t = 0.05   # epochs with inexplicably large gaps between frame timestamps\n",
    "max_dist_travel = 26 # max adjusted distance traveled value. defined as: (dist-dist.rolling(3, center=True).median()).abs(), epochs with multiple fish but appeared as 1 fish have aberrent displ jumps - YZ 20.05.13\n",
    "min_verticle_vel = -5 # (mm/s) max verdical displacement difference. Used to exclude fish bout downwards.\n",
    "epoch_buf = 2        # truncate the epochs from both ends. In Matlab code, 3 was excluded in analyzeFreeVerticalGrouped2 and another 5 was dropped in GrabFishAngel\n",
    "# However, in analyzeFreeVerticalGrouped2, line epochDex:epochStop(i):epochStop(i+1) \n",
    "#     incorrectly truncated the beginning of the epoch by 1 and the end by 3. \n",
    "\n",
    "# Other parameters\n",
    "scale = 60           #(pix/mm) ofr BlackFly verticle fish rigs 1-6\n",
    "sm_window_for_filter = 9     # smoothing\n",
    "sm_window_for_angVel = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read LabView files and truncate epochs\n",
    "\"the LabView code returns a value to mark an \"epoch,\" which is a continuous series of frames that had at least one identified particle + lines to output head location in addition to body, for detection direction of movement.\" - analyzeFreeVerticalGrouped2.m by DEE 1.30.2015\n",
    "\n",
    "Note: in DEE's code, the first 1 and last 3 timepoints per epoch were dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "File 200313 16.21.02.dlm loaded\n.\n"
    }
   ],
   "source": [
    "# Read .dlm and truncate epochs\n",
    "\n",
    "file_path = os.getcwd() # need to be defined/entered when calling as a function or use command line input\n",
    "# filenames = os.listdir\n",
    "filenames = glob.glob(f\"{file_path}/data/*.dlm\") # subject to change \n",
    "file_i = 0 # get 1 file for testing\n",
    "col_names = ['time','fishNum','ang','absx','absy','absHeadx','absHeady','col7','epochNum','fishLen']\n",
    "\n",
    "try:\n",
    "    raw = pd.read_csv(filenames[file_i], sep=\"\\t\",names = col_names) # load .dlm\n",
    "except:\n",
    "    print(f\"No .dlm file found under {file_path}/data/\")\n",
    "else:\n",
    "    print(f\"File {filenames[file_i][-19:]} loaded\")\n",
    "\n",
    "# Clear original time data stored in the first row\n",
    "raw.loc[0,'time'] = 0\n",
    "# apply filters and reset_index to speed up future calculations\n",
    "raw_truncate = raw_filter(raw).reset_index().rename(columns={'index': 'oriIndex'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time/date calc. & Filtering for delta t\n",
    "Only keep epochs longer than the duration threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".\n"
    }
   ],
   "source": [
    "# Calculate time/date and Filter for delta t\n",
    "\n",
    "# Initialize dataframe for analyzed epochs\n",
    "ana = pd.DataFrame()\n",
    "# Transfer original index, epochNum, and time info\n",
    "ana = raw_truncate[['oriIndex','epochNum','ang','absy']].copy()\n",
    "# Calculate time difference\n",
    "#   ! use .assign() for assigning new columns ! avoid df[['newCol]] or df.loc[:,'newCol']\n",
    "ana = ana.assign(\n",
    "    deltaT = grp_by_epoch(raw_truncate).time.diff()\n",
    ")\n",
    "# Get the start time from file name\n",
    "datetime_frmt = '%y%m%d %H.%M.%S'\n",
    "time_stamp = filenames[file_i][-19:-4]\n",
    "start_time = datetime.strptime(time_stamp, datetime_frmt)\n",
    "# Calculate absolute datetime for each timepoint. DataFrame calculation is faster than using .apply()\n",
    "ana.insert(1,\n",
    "    'absTime', start_time + pd.to_timedelta(raw_truncate['time'].values, unit=('s'))\n",
    ")\n",
    "\n",
    "# Calculate coordinates\n",
    "#   dataframe subduction is faster than cumulative difference. \n",
    "#   Use .values to convert into arrays to further speed up\n",
    "centered_coordinates = pd.DataFrame((\n",
    "    raw_truncate[['absx','absy','absHeadx','absHeady','ang']].values\n",
    "    - grp_by_epoch(raw_truncate)[['absx','absy','absHeadx','absHeady','ang']].transform('first').values\n",
    "), columns = ['x','y','headx','heady','centeredAng'])\n",
    "\n",
    "ana = ana.join(centered_coordinates)\n",
    "\n",
    "# Apply filters\n",
    "ana_f = dur_y_x_filter(ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for displacement, angular velocity, angular acceleration\n",
    "See code comments for details. An adjusted distance filter is added (YZ 2020.05) to exclude epochs with sudden large movements caused by incorrect detection or fish swimming on the edge of the FOV\n",
    "\n",
    "### Notes\n",
    "displacement = diff(sqrt{[absx(i+1)]^2+[absy(i+1)]^2})\n",
    "\n",
    "distance = sqrt(x.diff()^2 + y.diff()^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".\n"
    }
   ],
   "source": [
    "# Calculate displacement, distance traveled, angular velocity, angular acceleration and filter epochs\n",
    "\n",
    "ana_f_g = grp_by_epoch(ana_f)\n",
    "ana_f = ana_f.assign(\n",
    "    # x and y velocity. using np.divide() has shorter runtime than df.div()\n",
    "    xvel = np.divide(ana_f_g['x'].diff().values, ana_f['deltaT'].values),\n",
    "    yvel = np.divide(ana_f_g['y'].diff().values, ana_f['deltaT'].values),\n",
    "    # use numpy function np.linalg.norm() for displacement and distance\n",
    "    dist = np.linalg.norm(ana_f_g[['x','y']].diff(), axis=1),\n",
    "    # since beginning coordinates for each epoch has been set to 0, just use (x, y) values for displ\n",
    "    displ = ana_f.groupby('epochNum', as_index=False, sort=False).apply(\n",
    "        lambda g: pd.Series((np.linalg.norm(g[['x','y']], axis=1)),index = g.index).diff()\n",
    "    ).reset_index(level=0, drop=True),\n",
    "    # array calculation is more time effieient\n",
    "    angVel = np.divide(ana_f_g['ang'].diff().values, ana_f['deltaT'].values)\n",
    ")\n",
    "# now let's get smoothed angular vel and angular acceleration\n",
    "ana_f = ana_f.assign(  \n",
    "    # loop through each epoch, get second to last angVel values (exclude the first one which is NA)\n",
    "    # calculate smooth, keep the index, assign to the new column\n",
    "    angVelSmoothed = pd.concat(\n",
    "        smooth_series_ML(g.tail(len(g)-1)['angVel'],sm_window_for_angVel) for i, g in grp_by_epoch(ana_f)\n",
    "    ),\n",
    "    angAccel = np.divide(grp_by_epoch(ana_f)['angVel'].diff().values, ana_f['deltaT'].values),\n",
    ")\n",
    "\n",
    "# Apply filters, drop previous index\n",
    "ana_ff = displ_dist_vel_filter(ana_f).reset_index(drop=True)\n",
    "\n",
    "# Acquire fish length from raw data\n",
    "ana_ff['fishLen'] = raw.loc[ana_ff['oriIndex'],'fishLen'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale results, extract data we care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale distance and velocity and tansfer data we care\n",
    "\n",
    "res = ana_ff.copy()\n",
    "# scale coordinate and displ, flip signs of y, positive = upwards\n",
    "res.loc[:,['y','heady','yvel']] = res[['y','heady','yvel']] * -1 / scale\n",
    "res.loc[:,['x','headx','xvel','displ','dist','fishLen']] = res[['x','headx','xvel','displ','dist','fishLen']] / scale\n",
    "# calculate swim speed\n",
    "res.loc[:,'swimSpeed'] = np.divide(res['dist'].values, res['deltaT'].values)\n",
    "# calculate swim velocity (displacement/)\n",
    "res.loc[:,'velocity'] = np.divide(res['displ'].values, res['deltaT'].values)\n",
    "# define fish length as 70th percentile of lengths captured.\n",
    "fish_length = grp_by_epoch(res)['fishLen'].agg(\n",
    "    fishLenEst = lambda l: l.quantile(0.7)\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "File 1: 200313 16.21.02.dlm analyzed successfully \n__\n\n"
    }
   ],
   "source": [
    "# Save analyzed data! Code is for MacOS. For Win users, see code at the bottom of this cell\n",
    "output_dir = f\"{file_path}/data/\"\n",
    "\n",
    "res.to_pickle(f'{file_path}/data/{file_i+1}_analyzed_epochs.pkl')\n",
    "fish_length.to_pickle(f'{file_path}/data/{file_i+1}_fish_length.pkl')\n",
    "print (f\"File {file_i+1}: {filenames[file_i][-19:]} analyzed successfully \\n__\\n\")\n",
    "\n",
    "# # Code below is for Win users\n",
    "# res.to_pickle('analyzed_epochs.pkl')\n",
    "# fish_length.to_pickle('fish_length.pkl')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bityzvfconda5c003cd747b248a28de2ce1a07e29099",
   "display_name": "Python 3.8.2 64-bit ('YZVF': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}